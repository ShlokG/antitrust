{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "df = pd.read_csv('doj_industry.csv')\n",
    "df2 = pd.read_csv('ftc_industry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811212\n",
      "517919\n",
      "522110\n",
      "561990\n",
      "561990\n",
      "562212\n",
      "561990\n",
      "523930\n",
      "517919\n",
      "517919\n",
      "517919\n",
      "423320\n",
      "333618\n",
      "211120\n",
      "522130\n",
      "111998\n",
      "621112\n",
      "531210\n",
      "517911\n",
      "423830\n",
      "522110\n",
      "551111\n",
      "522110\n",
      "522110\n",
      "482111\n",
      "221118\n",
      "541219\n",
      "522110\n",
      "221118\n",
      "522110\n",
      "551111\n",
      "115116\n",
      "213112\n",
      "522110\n",
      "541511\n",
      "515120\n",
      "238990\n",
      "541110\n",
      "541618\n",
      "443141\n",
      "445299\n",
      "334418\n",
      "551111\n",
      "623110\n",
      "221118\n",
      "524126\n",
      "541618\n",
      "517911\n",
      "334511\n",
      "561990\n",
      "423510\n",
      "423320\n",
      "424990\n",
      "522110\n",
      "518210\n",
      "811212\n",
      "611699\n",
      "236220\n",
      "522110\n",
      "541511\n",
      "524114\n",
      "517311\n",
      "424490\n",
      "221118\n",
      "517311\n",
      "523930\n",
      "541618\n",
      "541614\n",
      "238990\n",
      "515120\n",
      "551111\n",
      "532282\n",
      "339999\n",
      "523930\n",
      "335999\n",
      "562212\n",
      "522110\n",
      "238110\n",
      "423320\n",
      "423450\n",
      "333314\n",
      "331221\n",
      "481111\n",
      "334511\n",
      "238990\n",
      "522110\n",
      "221118\n",
      "221118\n",
      "551111\n",
      "115116\n",
      "115116\n",
      "515112\n",
      "541810\n",
      "541810\n",
      "811412\n",
      "339999\n",
      "541810\n",
      "515112\n",
      "423840\n",
      "488119\n",
      "443142\n",
      "445299\n",
      "518210\n",
      "522110\n",
      "522110\n",
      "541810\n",
      "423690\n",
      "562211\n",
      "333924\n",
      "423990\n",
      "213112\n",
      "423830\n",
      "115210\n",
      "517919\n",
      "424490\n",
      "423830\n",
      "621111\n",
      "523120\n",
      "518210\n",
      "236116\n",
      "518210\n",
      "445299\n",
      "523930\n",
      "522110\n",
      "523120\n",
      "237990\n",
      "531210\n",
      "445110\n",
      "327992\n",
      "621111\n",
      "524210\n",
      "811412\n",
      "812310\n",
      "621610\n",
      "541219\n",
      "326199\n"
     ]
    }
   ],
   "source": [
    "main = \"https://siccode.com/\"\n",
    "url = \"https://siccode.com/en/search/\"\n",
    "for i in range(len(df.index)):\n",
    "    request = url + df.loc[i,'Acquirer_New']\n",
    "    response = requests.get(request)\n",
    "    root = BeautifulSoup(response.content, \"lxml\")\n",
    "    namers = root.find_all('h5', class_=\"business-name\")\n",
    "    \n",
    "    comp_nm = df.loc[i, 'Acquirer_Parent'].lower()\n",
    "    url_comp = df.loc[i, 'Acquirer_New'].lower()\n",
    "    \n",
    "    for j in range(len(namers)):\n",
    "        testing = namers[j].get_text().lower()\n",
    "        mat_ind = testing.index(\" \") if \" \" in testing else None\n",
    "        mat2 = None\n",
    "        if mat_ind != None:\n",
    "            mat2 = testing[mat_ind+1: len(testing)].index(\" \") if \" \" in testing[mat_ind+1:len(testing)] else None\n",
    "        \n",
    "        if (testing == comp_nm or\n",
    "            ((url_comp.find(\"%20\") != -1) and (testing == url_comp[0:url_comp.index(\"%20\")])) or\n",
    "        (mat_ind != None and comp_nm[0:mat_ind] == testing[0:mat_ind] and \n",
    "         ((mat2 == None and (testing[mat_ind+1: len(testing)].find(\"inc\") or\n",
    "                          testing[mat_ind+1: len(testing)].find(\"co\"))) or\n",
    "         (mat2 != None and len(comp_nm) > mat_ind+1 and comp_nm[mat_ind+1:len(comp_nm)].find(testing[mat_ind+1: mat2]))))):\n",
    "            \n",
    "            if len(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")) <= j:\n",
    "                break\n",
    "            else:\n",
    "                href = str(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")[j])\n",
    "                href = href[58:len(href)]\n",
    "                first = href.index('\"')\n",
    "                second = href[first+1:len(href)].index('\"')\n",
    "                href = href[first+1:second]\n",
    "            \n",
    "                href = main + href\n",
    "            \n",
    "                # Go to website of company and get NAICS Code\n",
    "                requester = requests.get(href)\n",
    "                child = BeautifulSoup(requester.content, \"lxml\")\n",
    "            \n",
    "                ans = child.find_all('span', class_= \"naics-item\")[0].get_text()\n",
    "                final = ans[0:ans.index(' ')]\n",
    "            \n",
    "                df.loc[i, 'Acquirer Industry Code'] = final\n",
    "                print(final)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443142\n",
      "443142\n",
      "481111\n",
      "522110\n",
      "515112\n",
      "424690\n",
      "515120\n",
      "562211\n",
      "515120\n",
      "515112\n",
      "515112\n",
      "524210\n",
      "515112\n",
      "481111\n",
      "424990\n",
      "512131\n",
      "541611\n",
      "339999\n",
      "481111\n",
      "512110\n",
      "481111\n",
      "445299\n",
      "482111\n",
      "551111\n",
      "622110\n",
      "517911\n",
      "522110\n",
      "522110\n",
      "522110\n",
      "321113\n",
      "515210\n",
      "334413\n",
      "622110\n",
      "522110\n",
      "311999\n",
      "531190\n",
      "523930\n",
      "562212\n",
      "541330\n",
      "621999\n",
      "622110\n",
      "454110\n",
      "551112\n",
      "453210\n",
      "332312\n",
      "424990\n",
      "522110\n",
      "334220\n",
      "561990\n",
      "531210\n",
      "551112\n",
      "221118\n",
      "238210\n",
      "522110\n",
      "238110\n",
      "541511\n",
      "518210\n",
      "334511\n",
      "721110\n",
      "311999\n",
      "541330\n",
      "221118\n",
      "511110\n"
     ]
    }
   ],
   "source": [
    "# DOJ Acquired (Almost same code as for acquirer)\n",
    "for i in range(len(df.index)):\n",
    "    request = url + df.loc[i,'Acquired_New']\n",
    "    response = requests.get(request)\n",
    "    root = BeautifulSoup(response.content, \"lxml\")\n",
    "    namers = root.find_all('h5', class_=\"business-name\")\n",
    "    \n",
    "    comp_nm = df.loc[i, 'Acquired_Parent'].lower()\n",
    "    url_comp = df.loc[i, 'Acquired_New'].lower()\n",
    "    \n",
    "    for j in range(len(namers)):\n",
    "        testing = namers[j].get_text().lower()\n",
    "        mat_ind = testing.index(\" \") if \" \" in testing else None\n",
    "        mat2 = None\n",
    "        if mat_ind != None:\n",
    "            mat2 = testing[mat_ind+1: len(testing)].index(\" \") if \" \" in testing[mat_ind+1:len(testing)] else None\n",
    "        \n",
    "        if (testing == comp_nm or\n",
    "            ((url_comp.find(\"%20\") != -1) and (testing == url_comp[0:url_comp.index(\"%20\")])) or\n",
    "        (mat_ind != None and comp_nm[0:mat_ind] == testing[0:mat_ind] and \n",
    "         ((mat2 == None and (testing[mat_ind+1: len(testing)].find(\"inc\") or\n",
    "                          testing[mat_ind+1: len(testing)].find(\"co\"))) or\n",
    "         (mat2 != None and len(comp_nm) > mat_ind+1 and comp_nm[mat_ind+1:len(comp_nm)].find(testing[mat_ind+1: mat2]))))):\n",
    "            \n",
    "            if len(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")) <= j:\n",
    "                break\n",
    "            else:\n",
    "                href = str(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")[j])\n",
    "                href = href[58:len(href)]\n",
    "                first = href.index('\"')\n",
    "                second = href[first+1:len(href)].index('\"')\n",
    "                href = href[first+1:second]\n",
    "            \n",
    "                href = main + href\n",
    "            \n",
    "                # Go to website of company and get NAICS Code\n",
    "                requester = requests.get(href)\n",
    "                child = BeautifulSoup(requester.content, \"lxml\")\n",
    "            \n",
    "                ans = child.find_all('span', class_= \"naics-item\")[0].get_text()\n",
    "                final = ans[0:ans.index(' ')]\n",
    "            \n",
    "                df.loc[i, 'Acquired Industry Code'] = final\n",
    "                print(final)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"doj_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df2.index)):\n",
    "    request = url + df2.loc[i,'Acquirer_New']\n",
    "    response = requests.get(request)\n",
    "    root = BeautifulSoup(response.content, \"lxml\")\n",
    "    namers = root.find_all('h5', class_=\"business-name\")\n",
    "    \n",
    "    comp_nm = df2.loc[i, 'Acquirer_Parent'].lower()\n",
    "    url_comp = df2.loc[i, 'Acquirer_New'].lower()\n",
    "    \n",
    "    for j in range(len(namers)):\n",
    "        testing = namers[j].get_text().lower()\n",
    "        mat_ind = testing.index(\" \") if \" \" in testing else None\n",
    "        mat2 = None\n",
    "        if mat_ind != None:\n",
    "            mat2 = testing[mat_ind+1: len(testing)].index(\" \") if \" \" in testing[mat_ind+1:len(testing)] else None\n",
    "        \n",
    "        if (testing == comp_nm or\n",
    "            ((url_comp.find(\"%20\") != -1) and (testing == url_comp[0:url_comp.index(\"%20\")])) or\n",
    "        (mat_ind != None and comp_nm[0:mat_ind] == testing[0:mat_ind] and \n",
    "         ((mat2 == None and (testing[mat_ind+1: len(testing)].find(\"inc\") or\n",
    "                          testing[mat_ind+1: len(testing)].find(\"co\"))) or\n",
    "         (mat2 != None and len(comp_nm) > mat_ind+1 and comp_nm[mat_ind+1:len(comp_nm)].find(testing[mat_ind+1: mat2]))))):\n",
    "            \n",
    "            if len(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")) == 0:\n",
    "                break\n",
    "            href = str(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")[j])\n",
    "            href = href[58:len(href)]\n",
    "            first = href.index('\"')\n",
    "            second = href[first+1:len(href)].index('\"')\n",
    "            href = href[first+1:second]\n",
    "            \n",
    "            href = main + href\n",
    "            \n",
    "            # Go to website of company and get NAICS Code\n",
    "            requester = requests.get(href)\n",
    "            child = BeautifulSoup(requester.content, \"lxml\")\n",
    "            \n",
    "            ans = child.find_all('span', class_= \"naics-item\")[0].get_text()\n",
    "            final = ans[0:ans.index(' ')]\n",
    "            \n",
    "            df2.loc[i, 'Acquirer Industry Code'] = final\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FTC Acquired Industry Code\n",
    "for i in range(len(df2.index)):\n",
    "    request = url + df2.loc[i,'Acquired_New']\n",
    "    response = requests.get(request)\n",
    "    root = BeautifulSoup(response.content, \"lxml\")\n",
    "    namers = root.find_all('h5', class_=\"business-name\")\n",
    "    \n",
    "    comp_nm = df2.loc[i, 'Acquired_Parent'].lower()\n",
    "    url_comp = df2.loc[i, 'Acquired_New'].lower()\n",
    "    \n",
    "    for j in range(len(namers)):\n",
    "        testing = namers[j].get_text().lower()\n",
    "        mat_ind = testing.index(\" \") if \" \" in testing else None\n",
    "        mat2 = None\n",
    "        if mat_ind != None:\n",
    "            mat2 = testing[mat_ind+1: len(testing)].index(\" \") if \" \" in testing[mat_ind+1:len(testing)] else None\n",
    "        \n",
    "        if (testing == comp_nm or\n",
    "            ((url_comp.find(\"%20\") != -1) and (testing == url_comp[0:url_comp.index(\"%20\")])) or\n",
    "        (mat_ind != None and comp_nm[0:mat_ind] == testing[0:mat_ind] and \n",
    "         ((mat2 == None and (testing[mat_ind+1: len(testing)].find(\"inc\") or\n",
    "                          testing[mat_ind+1: len(testing)].find(\"co\"))) or\n",
    "         (mat2 != None and len(comp_nm) > mat_ind+1 and comp_nm[mat_ind+1:len(comp_nm)].find(testing[mat_ind+1: mat2]))))):\n",
    "            \n",
    "            if len(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")) == 0:\n",
    "                break\n",
    "            href = str(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")[j])\n",
    "            href = href[58:len(href)]\n",
    "            first = href.index('\"')\n",
    "            second = href[first+1:len(href)].index('\"')\n",
    "            href = href[first+1:second]\n",
    "            \n",
    "            href = main + href\n",
    "            \n",
    "            # Go to website of company and get NAICS Code\n",
    "            requester = requests.get(href)\n",
    "            child = BeautifulSoup(requester.content, \"lxml\")\n",
    "            \n",
    "            ans = child.find_all('span', class_= \"naics-item\")[0].get_text()\n",
    "            final = ans[0:ans.index(' ')]\n",
    "            \n",
    "            df2.loc[i, 'Acquired Industry Code'] = final\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv(\"ftc_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
