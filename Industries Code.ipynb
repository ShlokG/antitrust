{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "df = pd.read_csv('doj_industry.csv')\n",
    "df2 = pd.read_csv('ftc_industry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main = \"https://siccode.com/\"\n",
    "url = \"https://siccode.com/en/search/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811212\n",
      "517919\n",
      "522110\n",
      "561990\n",
      "561990\n",
      "562212\n",
      "561990\n",
      "523930\n",
      "517919\n",
      "517919\n",
      "517919\n",
      "423320\n",
      "333618\n",
      "211120\n",
      "522130\n",
      "111998\n",
      "621112\n",
      "531210\n",
      "517911\n",
      "423830\n",
      "522110\n",
      "551111\n",
      "522110\n",
      "522110\n",
      "482111\n",
      "221118\n",
      "541219\n",
      "522110\n",
      "221118\n",
      "522110\n",
      "551111\n",
      "115116\n",
      "213112\n",
      "522110\n",
      "541511\n",
      "515120\n",
      "238990\n",
      "541110\n",
      "541618\n",
      "443141\n",
      "445299\n",
      "334418\n",
      "551111\n",
      "623110\n",
      "221118\n",
      "524126\n",
      "541618\n",
      "517911\n",
      "334511\n",
      "561990\n",
      "423510\n",
      "423320\n",
      "424990\n",
      "522110\n",
      "518210\n",
      "811212\n",
      "611699\n",
      "236220\n",
      "522110\n",
      "541511\n",
      "524114\n",
      "517311\n",
      "424490\n",
      "221118\n",
      "517311\n",
      "523930\n",
      "541618\n",
      "541614\n",
      "238990\n",
      "515120\n",
      "551111\n",
      "532282\n",
      "339999\n",
      "523930\n",
      "335999\n",
      "562212\n",
      "522110\n",
      "238110\n",
      "423320\n",
      "423450\n",
      "333314\n",
      "331221\n",
      "481111\n",
      "334511\n",
      "238990\n",
      "522110\n",
      "221118\n",
      "221118\n",
      "551111\n",
      "115116\n",
      "115116\n",
      "515112\n",
      "541810\n",
      "541810\n",
      "811412\n",
      "339999\n",
      "541810\n",
      "515112\n",
      "423840\n",
      "488119\n",
      "443142\n",
      "445299\n",
      "518210\n",
      "522110\n",
      "522110\n",
      "541810\n",
      "423690\n",
      "562211\n",
      "333924\n",
      "423990\n",
      "213112\n",
      "423830\n",
      "115210\n",
      "517919\n",
      "424490\n",
      "423830\n",
      "621111\n",
      "523120\n",
      "518210\n",
      "236116\n",
      "518210\n",
      "445299\n",
      "523930\n",
      "522110\n",
      "523120\n",
      "237990\n",
      "531210\n",
      "445110\n",
      "327992\n",
      "621111\n",
      "524210\n",
      "811412\n",
      "812310\n",
      "621610\n",
      "541219\n",
      "326199\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df.index)):\n",
    "    request = url + df.loc[i,'Acquirer_New']\n",
    "    response = requests.get(request)\n",
    "    root = BeautifulSoup(response.content, \"lxml\")\n",
    "    namers = root.find_all('h5', class_=\"business-name\")\n",
    "    \n",
    "    comp_nm = df.loc[i, 'Acquirer_Parent'].lower()\n",
    "    url_comp = df.loc[i, 'Acquirer_New'].lower()\n",
    "    \n",
    "    for j in range(len(namers)):\n",
    "        testing = namers[j].get_text().lower()\n",
    "        mat_ind = testing.index(\" \") if \" \" in testing else None\n",
    "        mat2 = None\n",
    "        if mat_ind != None:\n",
    "            mat2 = testing[mat_ind+1: len(testing)].index(\" \") if \" \" in testing[mat_ind+1:len(testing)] else None\n",
    "        \n",
    "        if (testing == comp_nm or\n",
    "            ((url_comp.find(\"%20\") != -1) and (testing == url_comp[0:url_comp.index(\"%20\")])) or\n",
    "        (mat_ind != None and comp_nm[0:mat_ind] == testing[0:mat_ind] and \n",
    "         ((mat2 == None and (testing[mat_ind+1: len(testing)].find(\"inc\") or\n",
    "                          testing[mat_ind+1: len(testing)].find(\"co\"))) or\n",
    "         (mat2 != None and len(comp_nm) > mat_ind+1 and comp_nm[mat_ind+1:len(comp_nm)].find(testing[mat_ind+1: mat2]))))):\n",
    "            \n",
    "            if len(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")) <= j:\n",
    "                break\n",
    "            else:\n",
    "                href = str(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")[j])\n",
    "                href = href[58:len(href)]\n",
    "                first = href.index('\"')\n",
    "                second = href[first+1:len(href)].index('\"')\n",
    "                href = href[first+1:second]\n",
    "            \n",
    "                href = main + href\n",
    "            \n",
    "                # Go to website of company and get NAICS Code\n",
    "                requester = requests.get(href)\n",
    "                child = BeautifulSoup(requester.content, \"lxml\")\n",
    "            \n",
    "                ans = child.find_all('span', class_= \"naics-item\")[0].get_text()\n",
    "                final = ans[0:ans.index(' ')]\n",
    "            \n",
    "                df.loc[i, 'Acquirer Industry Code'] = final\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443142\n",
      "443142\n",
      "481111\n",
      "522110\n",
      "515112\n",
      "424690\n",
      "515120\n",
      "562211\n",
      "515120\n",
      "515112\n",
      "515112\n",
      "524210\n",
      "515112\n",
      "481111\n",
      "424990\n",
      "512131\n",
      "541611\n",
      "339999\n",
      "481111\n",
      "512110\n",
      "481111\n",
      "445299\n",
      "482111\n",
      "551111\n",
      "622110\n",
      "517911\n",
      "522110\n",
      "522110\n",
      "522110\n",
      "321113\n",
      "515210\n",
      "334413\n",
      "622110\n",
      "522110\n",
      "311999\n",
      "531190\n",
      "523930\n",
      "562212\n",
      "541330\n",
      "621999\n",
      "622110\n",
      "454110\n",
      "551112\n",
      "453210\n",
      "332312\n",
      "424990\n",
      "522110\n",
      "334220\n",
      "561990\n",
      "531210\n",
      "551112\n",
      "221118\n",
      "238210\n",
      "522110\n",
      "238110\n",
      "541511\n",
      "518210\n",
      "334511\n",
      "721110\n",
      "311999\n",
      "541330\n",
      "221118\n",
      "511110\n",
      "541380\n",
      "541611\n",
      "517919\n",
      "522110\n",
      "238320\n",
      "238110\n",
      "511199\n",
      "333924\n",
      "481111\n",
      "811219\n",
      "311421\n",
      "541611\n",
      "522110\n",
      "541690\n",
      "515112\n",
      "512110\n",
      "541611\n",
      "562219\n",
      "236116\n",
      "325611\n",
      "339999\n",
      "551111\n",
      "522110\n",
      "541990\n",
      "326199\n",
      "238210\n",
      "424720\n",
      "541330\n",
      "522110\n",
      "541330\n",
      "541380\n",
      "481111\n",
      "481111\n",
      "332913\n",
      "722511\n",
      "541618\n",
      "424490\n"
     ]
    }
   ],
   "source": [
    "# DOJ Acquired (Almost same code as for acquirer)\n",
    "for i in range(len(df.index)):\n",
    "    request = url + df.loc[i,'Acquired_New']\n",
    "    response = requests.get(request)\n",
    "    root = BeautifulSoup(response.content, \"lxml\")\n",
    "    namers = root.find_all('h5', class_=\"business-name\")\n",
    "    \n",
    "    comp_nm = df.loc[i, 'Acquired_Parent'].lower()\n",
    "    url_comp = df.loc[i, 'Acquired_New'].lower()\n",
    "    \n",
    "    for j in range(len(namers)):\n",
    "        testing = namers[j].get_text().lower()\n",
    "        mat_ind = testing.index(\" \") if \" \" in testing else None\n",
    "        mat2 = None\n",
    "        if mat_ind != None:\n",
    "            mat2 = testing[mat_ind+1: len(testing)].index(\" \") if \" \" in testing[mat_ind+1:len(testing)] else None\n",
    "        \n",
    "        if (testing == comp_nm or\n",
    "            ((url_comp.find(\"%20\") != -1) and (testing == url_comp[0:url_comp.index(\"%20\")])) or\n",
    "        (mat_ind != None and comp_nm[0:mat_ind] == testing[0:mat_ind] and \n",
    "         ((mat2 == None and (testing[mat_ind+1: len(testing)].find(\"inc\") or\n",
    "                          testing[mat_ind+1: len(testing)].find(\"co\"))) or\n",
    "         (mat2 != None and len(comp_nm) > mat_ind+1 and comp_nm[mat_ind+1:len(comp_nm)].find(testing[mat_ind+1: mat2]))))):\n",
    "            \n",
    "            if len(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")) <= j:\n",
    "                break\n",
    "            else:\n",
    "                href = str(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")[j])\n",
    "                href = href[58:len(href)]\n",
    "                first = href.index('\"')\n",
    "                second = href[first+1:len(href)].index('\"')\n",
    "                href = href[first+1:second]\n",
    "            \n",
    "                href = main + href\n",
    "            \n",
    "                # Go to website of company and get NAICS Code\n",
    "                requester = requests.get(href)\n",
    "                child = BeautifulSoup(requester.content, \"lxml\")\n",
    "            \n",
    "                ans = child.find_all('span', class_= \"naics-item\")[0].get_text()\n",
    "                final = ans[0:ans.index(' ')]\n",
    "            \n",
    "                df.loc[i, 'Acquired Industry Code'] = final\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_again = df.copy()\n",
    "for i in range(len(df.index)):\n",
    "    if (pd.isnull(df.loc[i, 'Acquirer Industry Code']) and not(pd.isnull(df.loc[i, 'Acquired Industry Code']))):\n",
    "        df_again.loc[i, 'Acquirer Industry Code'] = df_again.loc[i, 'Acquired Industry Code']\n",
    "    elif pd.isnull(df.loc[i, 'Acquired Industry Code']) and not(pd.isnull(df.loc[i, 'Acquirer Industry Code'])):\n",
    "        df_again.loc[i, 'Acquired Industry Code'] = df_again.loc[i, 'Acquirer Industry Code']\n",
    "    elif not(pd.isnull(df.loc[i, 'Acquirer Industry Code'])) and not(pd.isnull(df.loc[i, 'Acquired Industry Code'])) and not(df3.loc[i, 'Acquirer Industry Code'] == df3.loc[i, 'Acquired Industry Code']):\n",
    "        df_again.loc[i, 'Acquirer Industry Code'] = str(df.loc[i, 'Acquirer Industry Code']) + \";\" + \n",
    "        str(df.loc[i, 'Acquired Industry Code'])\n",
    "        df_again.loc[i, 'Acquired Industry Code'] = str(df.loc[i, 'Acquirer Industry Code']) + \";\" + \n",
    "        str(df.loc[i, 'Acquired Industry Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_again.to_csv(\"doj_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711219\n",
      "541380\n",
      "621111\n",
      "211120\n",
      "621492\n",
      "335312\n",
      "334413\n",
      "541380\n",
      "517911\n",
      "423990\n",
      "424990\n",
      "443142\n",
      "621111\n",
      "622110\n",
      "522291\n",
      "522291\n",
      "621112\n",
      "561110\n",
      "561110\n",
      "424210\n",
      "325412\n",
      "447190\n",
      "339999\n",
      "551112\n",
      "452210\n",
      "541720\n",
      "561990\n",
      "423450\n",
      "453998\n",
      "522291\n",
      "621111\n",
      "518210\n",
      "325412\n",
      "561990\n",
      "325412\n",
      "325412\n",
      "325412\n",
      "325412\n",
      "334413\n",
      "711219\n",
      "561910\n",
      "621112\n",
      "624190\n",
      "423510\n",
      "423450\n",
      "621111\n",
      "524210\n",
      "445120\n",
      "423990\n",
      "333914\n",
      "325412\n",
      "541330\n",
      "339999\n",
      "621111\n",
      "333914\n",
      "446110\n",
      "325412\n",
      "325412\n",
      "454310\n",
      "621492\n",
      "236116\n",
      "531120\n",
      "237110\n",
      "522291\n",
      "621111\n",
      "621111\n",
      "446110\n",
      "621111\n",
      "531210\n",
      "423990\n",
      "446110\n",
      "813910\n",
      "621492\n",
      "541720\n",
      "541810\n",
      "423450\n",
      "621111\n",
      "334513\n",
      "312111\n",
      "423450\n",
      "325998\n",
      "522291\n",
      "445110\n",
      "522291\n",
      "424690\n",
      "811212\n",
      "541611\n",
      "621111\n",
      "423990\n",
      "541110\n",
      "423990\n",
      "424690\n",
      "325998\n",
      "452319\n",
      "541611\n",
      "621111\n",
      "624190\n",
      "424210\n",
      "621492\n",
      "518210\n",
      "423610\n",
      "213112\n",
      "561990\n",
      "334519\n",
      "423450\n",
      "621511\n",
      "531190\n",
      "325412\n",
      "339999\n",
      "621492\n",
      "325412\n",
      "621492\n",
      "423450\n",
      "339112\n",
      "221210\n",
      "238110\n",
      "325998\n",
      "324110\n",
      "447190\n",
      "522291\n",
      "711212\n",
      "212111\n",
      "531120\n",
      "339999\n",
      "221118\n",
      "621111\n",
      "621511\n",
      "237110\n",
      "486990\n",
      "445110\n",
      "541330\n",
      "423990\n",
      "621511\n",
      "541720\n",
      "522130\n",
      "423220\n",
      "424690\n",
      "325611\n",
      "523910\n",
      "621111\n",
      "324110\n",
      "447190\n",
      "441110\n",
      "621999\n",
      "522291\n",
      "541715\n",
      "541618\n",
      "541618\n",
      "423990\n",
      "221118\n",
      "423610\n",
      "447190\n",
      "445110\n",
      "221118\n",
      "325998\n",
      "522291\n",
      "541720\n",
      "621111\n",
      "561990\n",
      "447190\n",
      "423690\n",
      "621112\n",
      "522130\n",
      "722511\n",
      "445110\n",
      "445110\n",
      "446110\n",
      "424210\n",
      "423990\n",
      "423990\n",
      "447190\n",
      "423990\n",
      "515210\n",
      "221118\n",
      "486210\n",
      "339999\n",
      "115210\n",
      "447190\n",
      "541191\n",
      "621112\n",
      "443142\n",
      "541219\n",
      "622110\n",
      "523999\n",
      "561990\n",
      "423990\n",
      "311999\n",
      "324110\n",
      "339112\n",
      "336310\n",
      "443142\n",
      "541110\n",
      "423840\n",
      "441310\n",
      "339999\n",
      "541330\n",
      "541618\n",
      "541618\n",
      "541511\n",
      "621492\n",
      "423450\n",
      "541940\n",
      "561110\n",
      "339112\n",
      "334511\n",
      "423450\n",
      "541330\n",
      "424210\n",
      "541320\n",
      "324110\n",
      "524127\n",
      "238220\n",
      "541511\n",
      "334511\n",
      "621210\n",
      "115116\n",
      "541618\n",
      "541810\n",
      "324110\n",
      "561990\n",
      "522130\n",
      "621111\n",
      "312111\n",
      "561612\n",
      "335312\n",
      "453998\n",
      "423690\n",
      "445120\n",
      "312111\n",
      "221210\n",
      "561990\n",
      "423310\n",
      "541810\n",
      "423320\n",
      "423310\n",
      "423830\n",
      "523910\n",
      "213112\n",
      "541715\n",
      "423450\n",
      "447190\n",
      "423520\n",
      "424490\n",
      "441310\n",
      "213112\n",
      "453110\n",
      "517919\n",
      "445120\n",
      "561990\n",
      "324110\n",
      "523910\n",
      "423990\n",
      "811412\n",
      "541330\n",
      "424210\n",
      "312111\n"
     ]
    }
   ],
   "source": [
    "# FTC Acquirer\n",
    "for i in range(len(df2.index)):\n",
    "    if df2.loc[i, 'Acquirer_Parent'] != \"Unknown\":\n",
    "        request = url + df2.loc[i,'Acquirer_New']\n",
    "        response = requests.get(request)\n",
    "        root = BeautifulSoup(response.content, \"lxml\")\n",
    "        namers = root.find_all('h5', class_=\"business-name\")\n",
    "    \n",
    "        comp_nm = df2.loc[i, 'Acquirer_Parent'].lower()\n",
    "        url_comp = df2.loc[i, 'Acquirer_New'].lower()\n",
    "    \n",
    "        for j in range(len(namers)):\n",
    "            testing = namers[j].get_text().lower()\n",
    "            mat_ind = testing.index(\" \") if \" \" in testing else None\n",
    "            mat2 = None\n",
    "            if mat_ind != None:\n",
    "                mat2 = testing[mat_ind+1: len(testing)].index(\" \") if \" \" in testing[mat_ind+1:len(testing)] else None\n",
    "        \n",
    "            if (testing == comp_nm or\n",
    "                ((url_comp.find(\"%20\") != -1) and (testing == url_comp[0:url_comp.index(\"%20\")])) or\n",
    "            (mat_ind != None and comp_nm[0:mat_ind] == testing[0:mat_ind] and \n",
    "             ((mat2 == None and (testing[mat_ind+1: len(testing)].find(\"inc\") or\n",
    "                              testing[mat_ind+1: len(testing)].find(\"co\"))) or\n",
    "             (mat2 != None and len(comp_nm) > mat_ind+1 and comp_nm[mat_ind+1:len(comp_nm)].find(testing[mat_ind+1: mat2]))))):\n",
    "            \n",
    "                if len(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")) <= j:\n",
    "                    break\n",
    "                href = str(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")[j])\n",
    "                href = href[58:len(href)]\n",
    "                first = href.index('\"')\n",
    "                second = href[first+1:len(href)].index('\"')\n",
    "                href = href[first+1:second]\n",
    "            \n",
    "                href = main + href\n",
    "            \n",
    "                # Go to website of company and get NAICS Code\n",
    "                requester = requests.get(href)\n",
    "                child = BeautifulSoup(requester.content, \"lxml\")\n",
    "            \n",
    "                ans = child.find_all('span', class_= \"naics-item\")[0].get_text()\n",
    "                final = ans[0:ans.index(' ')]\n",
    "            \n",
    "                df2.loc[i, 'Acquirer Industry Code'] = final\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511210\n",
      "423450\n",
      "621111\n",
      "621111\n",
      "325320\n",
      "561110\n",
      "333999\n",
      "445110\n",
      "541512\n",
      "423450\n",
      "541940\n",
      "453210\n",
      "622110\n",
      "339112\n",
      "325412\n",
      "325412\n",
      "339999\n",
      "445110\n",
      "446110\n",
      "444190\n",
      "424940\n",
      "423450\n",
      "452319\n",
      "621511\n",
      "541810\n",
      "445110\n",
      "812210\n",
      "522291\n",
      "621111\n",
      "445110\n",
      "325412\n",
      "621111\n",
      "621340\n",
      "621111\n",
      "325412\n",
      "811111\n",
      "424690\n",
      "423510\n",
      "541910\n",
      "811212\n",
      "423450\n",
      "423420\n",
      "444130\n",
      "621511\n",
      "621999\n",
      "221118\n",
      "622110\n",
      "531210\n",
      "423990\n",
      "621111\n",
      "621511\n",
      "424690\n",
      "621111\n",
      "446110\n",
      "511210\n",
      "621111\n",
      "115210\n",
      "812210\n",
      "339999\n",
      "423490\n",
      "423450\n",
      "722511\n",
      "424690\n",
      "524126\n",
      "339113\n",
      "541715\n",
      "325412\n",
      "522130\n",
      "311942\n",
      "541940\n",
      "311999\n",
      "424210\n",
      "485999\n",
      "221118\n",
      "424130\n",
      "541330\n",
      "423450\n",
      "812210\n",
      "541720\n",
      "423420\n",
      "237110\n",
      "446110\n",
      "621492\n",
      "115210\n",
      "621111\n",
      "621111\n",
      "621111\n",
      "811412\n",
      "531210\n",
      "212399\n",
      "213112\n",
      "622110\n",
      "621991\n",
      "541511\n",
      "447190\n",
      "447190\n",
      "621111\n",
      "423610\n",
      "325412\n",
      "447190\n",
      "621991\n",
      "211120\n",
      "325412\n",
      "445291\n",
      "445120\n",
      "541618\n",
      "324110\n",
      "424690\n",
      "445110\n",
      "213112\n",
      "445110\n",
      "423320\n",
      "522130\n",
      "311942\n",
      "541810\n",
      "445120\n",
      "541611\n",
      "445120\n",
      "327120\n",
      "561990\n",
      "447190\n",
      "541191\n",
      "453210\n",
      "488510\n",
      "622110\n",
      "541330\n",
      "541618\n",
      "311999\n",
      "221210\n",
      "325611\n",
      "238220\n",
      "524126\n",
      "423830\n",
      "339999\n",
      "444130\n",
      "515112\n",
      "423390\n",
      "443141\n",
      "447190\n",
      "551112\n",
      "551112\n",
      "445120\n",
      "524127\n",
      "523120\n",
      "561499\n",
      "523930\n",
      "236116\n",
      "522110\n",
      "561612\n",
      "811111\n",
      "339112\n",
      "424210\n",
      "445110\n",
      "424720\n",
      "524126\n",
      "445110\n",
      "445110\n",
      "447190\n",
      "238210\n",
      "541613\n",
      "551112\n",
      "446110\n",
      "423990\n",
      "424910\n",
      "423520\n",
      "621511\n",
      "423610\n",
      "452210\n",
      "511130\n",
      "238220\n",
      "423990\n",
      "332710\n",
      "424690\n",
      "333249\n",
      "561990\n",
      "517919\n",
      "442210\n"
     ]
    }
   ],
   "source": [
    "# FTC Acquired Industry Code\n",
    "for i in range(len(df2.index)):\n",
    "    if df2.loc[i, 'Acquired_Parent'] != \"Unknown\":\n",
    "        request = url + df2.loc[i,'Acquired_New']\n",
    "        response = requests.get(request)\n",
    "        root = BeautifulSoup(response.content, \"lxml\")\n",
    "        namers = root.find_all('h5', class_=\"business-name\")\n",
    "    \n",
    "        comp_nm = df2.loc[i, 'Acquired_Parent'].lower()\n",
    "        url_comp = df2.loc[i, 'Acquired_New'].lower()\n",
    "    \n",
    "        for j in range(len(namers)):\n",
    "            testing = namers[j].get_text().lower()\n",
    "            mat_ind = testing.index(\" \") if \" \" in testing else None\n",
    "            mat2 = None\n",
    "            if mat_ind != None:\n",
    "                mat2 = testing[mat_ind+1: len(testing)].index(\" \") if \" \" in testing[mat_ind+1:len(testing)] else None\n",
    "        \n",
    "            if (testing == comp_nm or\n",
    "                ((url_comp.find(\"%20\") != -1) and (testing == url_comp[0:url_comp.index(\"%20\")])) or\n",
    "            (mat_ind != None and comp_nm[0:mat_ind] == testing[0:mat_ind] and \n",
    "             ((mat2 == None and (testing[mat_ind+1: len(testing)].find(\"inc\") or\n",
    "                              testing[mat_ind+1: len(testing)].find(\"co\"))) or\n",
    "             (mat2 != None and len(comp_nm) > mat_ind+1 and comp_nm[mat_ind+1:len(comp_nm)].find(testing[mat_ind+1: mat2]))))):\n",
    "            \n",
    "                if len(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")) <= j:\n",
    "                    break\n",
    "                href = str(root.find_all('div', class_=\"row-fluid result-row company-list businesses\")[j])\n",
    "                href = href[58:len(href)]\n",
    "                first = href.index('\"')\n",
    "                second = href[first+1:len(href)].index('\"')\n",
    "                href = href[first+1:second]\n",
    "            \n",
    "                href = main + href\n",
    "            \n",
    "                # Go to website of company and get NAICS Code\n",
    "                requester = requests.get(href)\n",
    "                child = BeautifulSoup(requester.content, \"lxml\")\n",
    "            \n",
    "                ans = child.find_all('span', class_= \"naics-item\")[0].get_text()\n",
    "                final = ans[0:ans.index(' ')]\n",
    "            \n",
    "                df2.loc[i, 'Acquired Industry Code'] = final\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "for i in range(len(df3.index)):\n",
    "    if not(pd.isnull(df3.loc[i, 'Acquirer Industry Code'])) and not(pd.isnull(df3.loc[i, 'Acquired Industry Code'])) and not(df3.loc[i, 'Acquirer Industry Code'] == df3.loc[i, 'Acquired Industry Code']):\n",
    "        acquirer = str(df3.loc[i, 'Acquirer Industry Code'])\n",
    "        df3.loc[i, 'Acquirer Industry Code'] = acquirer + \";\" + str(df3.loc[i, 'Acquired Industry Code'])\n",
    "        df3.loc[i, 'Acquired Industry Code'] = acquirer + \";\" + str(df3.loc[i, 'Acquired Industry Code'])\n",
    "    elif (pd.isnull(df3.loc[i, 'Acquirer Industry Code']) and not(pd.isnull(df3.loc[i, 'Acquired Industry Code']))):\n",
    "        df3.loc[i, 'Acquirer Industry Code'] = df3.loc[i, 'Acquired Industry Code']\n",
    "    elif (pd.isnull(df3.loc[i, 'Acquired Industry Code']) and not(pd.isnull(df3.loc[i, 'Acquirer Industry Code']))):\n",
    "        df3.loc[i, 'Acquired Industry Code'] = df3.loc[i, 'Acquirer Industry Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"ftc_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
